---
title: "Active Tigger"
subtitle: "Accélérer la classification de données textuelles"
author: "Émilien Schultz - Julien Boelaert - Étienne Ollion"
format: 
    revealjs:
        slide-number: true
        fontsize: 25pt
---


## Constat de départ

- *Croissance* des pratiques numériques en sciences sociales
    - Importance d'outiller / clarifier ces dimensions CSS
- *Abondance* de données textuelles
    - Coût important (humain/argent)
    - Corpus déséquilibrés (événements rares)
- Arrivée des *modèles pré-entraînés*
    - Transformers (BERT en 2018)
    - (update) le zéro-shot et les modèles multi-tâches

## Lien avec "le chercheur augmenté"[^augmented]

- *Déléguer* les tâches automatisables avec une qualité suffisante
- *Étendre* sur des corpus plus larges
- *Accompagner* les bonnes pratiques dans des outils

> « The experiment yields a clear conclusion to both questions. Even on complex tasks, a well-trained supervised model using sequential learning can equal, and sometimes even surpass human annotation » [Do et al., 2022, p. 6]

[^augmented]: Do, Salomé, Etienne Ollion, et Rubing Shen. « The Augmented Social Scientist ». Sociological Methods and Research, 2022.

## Active Tigger : logiciel open source pour la recherche en SHS

- Tâches principales :
    - **Faciliter** l'annotation multi-classes de corpus textuels (heuristique)
    - **Accélérer** cette annotation sur de grands corpus textuels (active)
- Tâches secondaires :
    - Explorer un corpus abondant
    - Collaborer sur l'annotation
    - Faciliter la stabilisation des schèmes de codage
    - Accélérer la constitution de sous-corpus

## Valeurs structurantes du projet [^ss]

- Open source & Open Science
- Logiciel scientifique
- Transparent / reproductible
- Équilibre entre normativité & modularité
- Ancré dans la recherche (évolutif)

[^ss]: *« models and software are entangled in science, and software does critical work that models cannot perform on their own » [Hocquet et al., 2024, p. 465]*

## Choix techniques actuels

- Tâches délimitées
- Implémenter une méthode [active learning](https://en.wikipedia.org/wiki/Active_learning_(machine_learning))
    - Annotation avec boucle d'AL
    - Fine-tune BERT + rétroaction (> zero-shot, cf. Chae & Davidson, 2023)
    - Étendre sur le corpus entier

::: {.callout-note title="Active Learning"}

Active learning aims to reduce the number of training instances. In contrast to filtering, it is applied during data collection (instead of after) to only annotate the most helpful or useful instances for training (Settles, 2012; Ren et al., 2021b). i.e. to assess usefulness of an instance without knowing its actual label, one can use the model uncertainty—assuming that labeling instances with the highest uncertainty is most helpful

:::

## Précisions 

- Transformer le texte en features
    - Plongement SBERT / autre
- AL adapté : 
    - Modèle frugal (ML classique) avec réintégration des prédictions
    - Petits batch
- Calcul de métriques et décisions laissés à l'utilisateur

## Implémentation : prototype RShiny 2022[^atshiny]

:::: {.columns}

::: {.column width="40%"}

- Produire un classifieur pour un très grand corpus
- Récupérer uniquement certains éléments dans un grand corpus
- Accélérer le codage exhaustif d'un corpus (avec la boucle AL)

:::

::: {.column width="60%"}

![](img/atr.png)

:::

::::

[^atshiny]: https://gitlab.univ-lille.fr/julien.boelaert/activetigger

## Exemple d'usage

Ollion & Boaelart : classifier les résumés d'articles en sociologie mobilisant des notions relevant du *genre*.

:::: {.columns}

::: {.column width="50%"}

- 115 revues, 47 000+
- Annotation O(1k) éléments
- Classifieur f1 > 0.9
- Prédiction sur le corpus
:::

::: {.column width="50%"}
![](img/evogenre.png)
:::

::::


## Depuis 2024 : refactorisation

Consolider l'architecture

- Ajouter du multiutilisateur
- Avoir un backend en Python
- Aller au-delà du prototypage

::: {.callout-note title="Refactorisation"}

- Python pour le backend (FASTAPI)
- Client dédié (React)

:::

*Un chantier encore en cours*

## Structure

Projet > données > annotations > modèle > prédictions

![](img/diagram.png)

## Démo - AT en version beta

- Une instance sur nos serveurs (GENES)
- Un jeu de données Genre
- Faire le tour des outils

<center>
[**go go démo** ✅](https://emilienschultz.github.io/activetigger)
</center>

## Les évolutions actuelles et futures

- Établir des comparatifs
- Intégrer au mieux les bonnes pratiques de constitution de corpus (Klie et al., 2024)
- Connecteurs avec les LLM-as-a-service
    - Prompt pour annoter
    - Règles de correction
- Autres modèles à fine-tuner ([Phi3](https://arxiv.org/abs/2404.14219)) ?

## Vous voulez tester ? Super !

<center>
![](img/betatest2.jpg)
</center>

## Comment contribuer ?

- [Github de Active Tigger](https://github.com/emilienschultz/activetigger/)
- Ouvrir des issues
- Entrer dans le  code
    - Inboarding possible
- **Quelles features à ajouter ?**

## Quelques références

- Ein-Dor, Liat, Alon Halfon, [...] Noam Slonim. « Active Learning for BERT: An Empirical Study ». In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 7949‑62. Online: Association for Computational Linguistics, 2020.
- Zhang, Zhisong, Emma Strubell, et Eduard Hovy. « A Survey of Active Learning for Natural Language Processing ». arXiv, 3 février 2023.
- Klie, Jan-Christoph, Richard Eckart De Castilho, et Iryna Gurevych. « Analyzing Dataset Annotation Quality Management in the Wild ». Computational Linguistics 50, nᵒ 3 (1 septembre 2024): 817‑66. 
- Chae, Youngjin, et Thomas Davidson. « Large Language Models for Text Classification: From Zero-Shot Learning to Instruction-Tuning », 24 août 2023.



## Contributeurs

Financement : GENES / DRARI / Progédo

- Julien Boaelaert
- Étienne Ollion
- Paul Girard (OuestWare)
- Emma Bonutti
- Léo Mignot

[www.css.cnrs.fr](www.css.cnrs.fr)



<!-- 
Keywords
- multiclass classification
- active learning
- open source
- open science
-->